{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019a7c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from numpy import random\n",
    "from scipy import linalg as LA\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb89265",
   "metadata": {},
   "source": [
    "axis=0，表示从每一列中，找最大值的索引\n",
    "axis=1，表示从每一行中，找最大值的列索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52c2a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_accuracy(predictLabel,Label):\n",
    "    count=0\n",
    "    label_1=np.zeros(Label.shape[0])\n",
    "    predLabel=[]\n",
    "    label_1=Label.argmax(axis=1)\n",
    "    prelabel=predictLabel.argmax(axis=1)\n",
    "    for j in list(range(Label.shape[0])):\n",
    "        if label_1[j]==prelabel[j]:\n",
    "            count+=1\n",
    "    return (round(count/len(Label),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a226848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tansig(x):\n",
    "    return (2/(1+np.exp(-2*x))-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c18a460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "760b7123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "216ab7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(data):\n",
    "    return (np.exp(data)-np.exp(-data))/(np.exp(data)+np.exp(-data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3611c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(data):\n",
    "    return np.maximum(data,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f56f4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pinv(A,reg):\n",
    "    return np.mat(reg*np.eye(A.shape[1])+A.T.dot(A)).I.dot(A.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be51b163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shrinkage(a,b):\n",
    "    return np.maximum(a-b,0)-np.maximum(-a-b,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4febf0",
   "metadata": {},
   "source": [
    "$w_{k+1} = (A^TA+\\rho I)^{-1}(Z^Tx+\\rho(o^k-u^k))$\\\\\\\n",
    "$o_{k+1}=S_{\\frac{\\lambda}{\\rho}}(W_{k+1}+u_k)$\\\\\\\n",
    "$u_{k+1}=u_k+(w_{k+1}-o_{k+1})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "559aa800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_bls(A,b):\n",
    "    lam=0.001\n",
    "    itrs=50\n",
    "    AA=A.T@A\n",
    "    m = A.shape[1]\n",
    "    n = b.shape[1]\n",
    "    x1=np.zeros([m,n])\n",
    "    wk=x1\n",
    "    ok=x1\n",
    "    uk=x1\n",
    "    # 使用np.mat能直接使用二维矩阵\n",
    "    # 将W的计算公式分为了两部分\n",
    "    L1 = np.mat(A@A.T+np.eye(A.shape[1])).I\n",
    "    L2 = L1@A.T@b\n",
    "    for i in range(itrs):\n",
    "        ck = L2+L1@(ok-uk)\n",
    "        \n",
    "        ok = shrinkage(ck+uk,lam)\n",
    "        uk=uk+wk-ok\n",
    "        wk=L1@(A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0646ebe0",
   "metadata": {},
   "source": [
    "scaler1是将每个窗口的特征进行缩放后并记录最大最小值，方便下一步transform时进行缩放\n",
    "transform过程：$X_{scaled} = \\frac{X-X_{min}}{X_{max}-X_{min}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3247e900",
   "metadata": {},
   "outputs": [],
   "source": [
    "#N1--每个窗口的特征节点数\n",
    "#N2--窗口数\n",
    "def BLS(train_x,train_y,test_x,test_y,s,c,N1,N2,N3):\n",
    "    L=0\n",
    "    #对训练集进行标准化，行方向上具有均值0，方差1\n",
    "    #假设矩阵形状为m*n\n",
    "    train_x=preprocessing.scale(train_x,axis=1)\\\n",
    "    # 将偏置加入到x中\n",
    "    #shape:m*(n+1)\n",
    "    FeatureOfInputDataWithBias=np.hstack([train_x,0.1*np.ones((train_x.shape[0],1))])\n",
    "    # # 存储每个窗口的权重矩阵\n",
    "    Beta1OfEachWindow = []\n",
    "    \n",
    "     #用于存储每个窗口的输出数据的最大最小值，用于后续的归一化处理\n",
    "    distOfMaxAndMin = []\n",
    "    minOfEachWindow = []\n",
    "    # 输出的归一化范围\n",
    "    ymin = 0\n",
    "    ymax = 1\n",
    "    train_acc_all = np.zeros([1,L+1])\n",
    "    test_acc = np.zeros([1,L+1])\n",
    "    train_time = np.zeros([1,L+1])\n",
    "    test_time = np.zeros([1,L+1])\n",
    "    time_start=time.time()#计时开始\n",
    "    OutputOfFeatureMappingLayer = np.zeros([train_x.shape[0],N2*N1])\n",
    "    for i in range(N2):\n",
    "        random.seed(i)\n",
    "        #shape: n+1 * N1\n",
    "        WeightOfEachWindow = 2* random.randn(train_x.shape[1]+1,N1)-1\n",
    "        #shape: m* N1\n",
    "        # 映射成N1个特征\n",
    "        FeatureOfEachWindow = FeatureOfInputDataWithBias@WeightOfEachWindow\n",
    "        # 缩放数据并记录\n",
    "        scaler1 = preprocessing.MinMaxScaler(feature_range=(0,1)).fit(FeatureOfEachWindow)\n",
    "        FeatureOfEachWindowAfterPreprocess = scaler1.transform(FeatureOfEachWindow)\n",
    "        betaOfEachWindow = sparse_bls(FeatureOfEachWindowAfterPreprocess,FeatureOfInputDataWithBias).T\n",
    "        Beta1OfEachWindow.append(betaOfEachWindow)\n",
    "        outputOfEachWindow = FeatureOfInputDataWithBias@betaOfEachWindow\n",
    "        \n",
    "        distOfMaxAndMin.append(np.max(outputOfEachWindow,axis =0) - np.min(outputOfEachWindow,axis=0))\n",
    "        minOfEachWindow.append(np.min(outputOfEachWindow,axis = 0))\n",
    "        \n",
    "         #输入乘完权重后，进行归一化\n",
    "        outputOfEachWindow = (outputOfEachWindow-minOfEachWindow[i])/distOfMaxAndMin[i]\n",
    "\n",
    "        # 计算完后填充进去\n",
    "        # 二维数组，对OutputFeatureMappingLayer进行列拓展，最后维度是N * (N1*N2)\n",
    "        OutputOfFeatureMappingLayer[:, N1*i:N1*(i+1)] = outputOfEachWindow\n",
    "        del outputOfEachWindow \n",
    "        del FeatureOfEachWindow \n",
    "        del weightOfEachWindow "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_learn",
   "language": "python",
   "name": "torch_learn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
